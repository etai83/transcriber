# Whisper model size: tiny, base, small, medium, large, large-v3, large-v3-turbo
# Use 'small' or larger for better Hebrew support
# large-v3-turbo is faster than large-v3 with similar accuracy
WHISPER_MODEL=large-v3-turbo

# Speaker diarization (requires pyannote models to be downloaded)
# Set to true to enable speaker detection, false to disable
ENABLE_DIARIZATION=true
# HuggingFace token for pyannote (get from hf.co/settings/tokens)
HF_TOKEN=your_huggingface_token_here

# Storage paths
AUDIO_STORAGE_PATH=./storage/audio
TRANSCRIPT_STORAGE_PATH=./storage/transcripts

# Database
DATABASE_URL=sqlite:///./transcriber.db

# Server
HOST=0.0.0.0
PORT=8000

# Default language (en, he, or auto for detection)
DEFAULT_LANGUAGE=auto
CORS_ORIGINS=["*"]

# AI Assistant settings
# Provider: "gemini" or "ollama" (default: ollama for local inference)
AI_ASSISTANT_PROVIDER=ollama
AI_ASSISTANT_ENABLED=true

# Gemini settings (when provider=gemini)
# Get your API key from: https://ai.google.dev/
GOOGLE_API_KEY=your_google_api_key_here
AI_ASSISTANT_MODEL=gemini-2.0-flash

# Ollama settings (when provider=ollama)
# Make sure Ollama is running: ollama serve
AI_ASSISTANT_OLLAMA_MODEL=llama3.1
AI_ASSISTANT_OLLAMA_URL=http://localhost:11434
